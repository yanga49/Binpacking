{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f21658-40c8-40c9-99d2-ec8c0b42e84f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Bin Packing Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ffdec9-9fcb-4a7b-910e-abecc6352210",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Authors:\n",
    "  - Akanksha Nehete, nehetea@mcmaster.ca\n",
    "  - Anna Yang, yanga49@mcmaster.ca\n",
    "  - Hamna Malik, malikh32@mcmaster.ca\n",
    "- Group ID on Avenue: 19 \n",
    "- Gitlab URL: https://gitlab.cas.mcmaster.ca/nehetea/l2-bin-packing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ba5415",
   "metadata": {},
   "source": [
    "# Library Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2166b346-058f-4619-9072-e6fbe608fa0e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from macpacking.reader import DatasetReader, BinppReader, JburkardtReader\n",
    "from macpacking.model  import Online, Offline\n",
    "import macpacking.algorithms.offline as offline\n",
    "from macpacking.__init__ import WeightSet, WeightStream # remove this when submitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21df8c2c-a6fa-434b-88c3-361404872819",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: _datasets/binpp/N1C1W1/N1C1W1_A.BPP.txt\n",
      "  - Bin Capacity: 100\n",
      "  - Objects to pack: [3, 7, 7, 10, 11, 13, 14, 17, 20, 21, 22, 23, 24, 25, 27, 28, 28, 29, 30, 30, 33, 33, 40, 40, 42, 44, 46, 49, 51, 52, 56, 61, 62, 67, 67, 69, 72, 74, 76, 85, 86, 87, 88, 91, 92, 92, 96, 96, 99, 99]\n"
     ]
    }
   ],
   "source": [
    "# demonstrating the reader for binpp and binpp-hard\n",
    "dataset = '_datasets/binpp/N1C1W1/N1C1W1_A.BPP.txt'\n",
    "reader: DatasetReader = BinppReader(dataset)\n",
    "print(f'Dataset: {dataset}')\n",
    "print(f'  - Bin Capacity: {reader.offline()[0]}')\n",
    "print(f'  - Objects to pack: {sorted(reader.offline()[1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94af42df",
   "metadata": {},
   "source": [
    "## T1: Implementation of Jburkardt Reader and Most Terrible Binpacking Algorithm\n",
    "See Report Body under code for explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a0034c4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: _datasets/jburkardt/p04_c.txt, _datasets/jburkardt/p04_w.txt\n",
      "  - Bin Capacity: 524\n",
      "  - Objects to pack: [9, 9, 10, 10, 10, 10, 10, 10, 12, 12, 12, 37, 37, 46, 84, 85, 106, 106, 106, 106, 127, 127, 127, 127, 127, 252, 252, 252, 252, 252, 252, 252, 442]\n"
     ]
    }
   ],
   "source": [
    "# implementation of reader for jburkardt\n",
    "datasetc = '_datasets/jburkardt/p04_c.txt'\n",
    "datasetw = '_datasets/jburkardt/p04_w.txt'\n",
    "reader: DatasetReader = JburkardtReader(datasetw, datasetc)\n",
    "print(f'Dataset: {datasetc}, {datasetw}')\n",
    "print(f'  - Bin Capacity: {reader.offline()[0]}')\n",
    "print(f'  - Objects to pack: {sorted(reader.offline()[1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e247325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_bins = 33\n",
      "[[9], [9], [10], [10], [10], [10], [10], [10], [12], [12], [12], [37], [37], [46], [84], [85], [106], [106], [106], [106], [127], [127], [127], [127], [127], [252], [252], [252], [252], [252], [252], [252], [442]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrating online implementation of most terrible binpacking algorithm\n",
    "import macpacking.algorithms.online as online\n",
    "strategy: Online = online.MostTerrible()\n",
    "result = strategy(reader.offline())\n",
    "print(f'nb_bins = {len(result[\"solution\"])}')\n",
    "print(f'{sorted(result[\"solution\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6ac256",
   "metadata": {},
   "source": [
    "## T2: Implementation and BenchMarking of Algorithms\n",
    "See Report body for Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6358d7c1-1777-4c63-af33-d4ebfea952a7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_bins = 8\n",
      "[[10, 9, 9], [106, 106, 106, 85, 84, 37], [127, 127, 127, 106, 37], [252, 127, 127, 12], [252, 252, 10, 10], [252, 252, 12], [252, 252, 12], [442, 46, 10, 10, 10]]\n"
     ]
    }
   ],
   "source": [
    "# finding the optimal solution using baseline\n",
    "import macpacking.algorithms.baseline as baseline\n",
    "strategy: Offline = baseline.BenMaier()\n",
    "result = strategy(reader.offline())\n",
    "print(f'nb_bins = {len(result)}')\n",
    "print(f'{sorted(result)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd41ee02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_bins = 8\n",
      "[[46, 37, 37, 12, 12, 12, 10, 10, 10, 10, 10, 10, 9, 9], [106, 106, 106, 85, 84], [127, 127, 127, 106], [252, 127, 127], [252, 252], [252, 252], [252, 252], [442]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrating usage of offline version of NextFit algorithm\n",
    "import macpacking.algorithms.online as online\n",
    "strategy: Offline = offline.NextFitDecreasing()\n",
    "result = strategy(reader.offline())\n",
    "print(f'nb_bins = {len(result[\"solution\"])}')\n",
    "print(f'{sorted(result[\"solution\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd49172b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_bins = 8\n",
      "[[10, 252, 127, 106, 10], [46, 12, 127, 10, 12, 252, 10], [85, 37, 252, 10], [106, 84, 252], [127, 37, 106, 127, 106], [252, 10, 9, 127, 12], [252, 252], [442, 9]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrating usage of online version of NextFit algorithm\n",
    "import macpacking.algorithms.online as online\n",
    "strategy: Online = online.NextFit()\n",
    "result = strategy(reader.offline())\n",
    "print(f'nb_bins = {len(result[\"solution\"])}')\n",
    "print(f'{sorted(result[\"solution\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d603303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_bins = 7\n",
      "[[106, 106, 106, 85, 84, 37], [127, 127, 127, 106, 37], [252, 127, 127, 9, 9], [252, 252, 10, 10], [252, 252, 10, 10], [252, 252, 10, 10], [442, 46, 12, 12, 12]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrating usage of offline version of FirstFit algorithm\n",
    "import macpacking.algorithms.offline as offline\n",
    "strategy: Offline = offline.FirstFitDecreasing()\n",
    "result = strategy(reader.online())\n",
    "print(f'nb_bins = {len(result[\"solution\"])}')\n",
    "print(f'{sorted(result[\"solution\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d9ebae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_bins = 8\n",
      "[[10, 252, 127, 106, 10, 12], [46, 127, 12, 252, 9, 37, 10, 10, 9, 12], [85, 252, 127], [106, 84, 252], [127, 37, 106, 127, 106, 10, 10], [252], [252, 252], [442]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrating usage of online version of FirstFit algorithm\n",
    "import macpacking.algorithms.online as online\n",
    "strategy: Online = online.FirstFit()\n",
    "result = strategy(reader.online())\n",
    "print(f'nb_bins = {len(result[\"solution\"])}')\n",
    "print(f'{sorted(result[\"solution\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c79d401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_bins = 8\n",
      "[[10, 9, 9], [106, 106, 106, 85, 84, 37], [127, 127, 127, 106, 37], [252, 127, 127, 12], [252, 252, 10, 10], [252, 252, 12], [252, 252, 12], [442, 46, 10, 10, 10]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrating usage of offline version of BestFit algorithm\n",
    "import macpacking.algorithms.offline as offline\n",
    "strategy: Offline = offline.BestFitDecreasing()\n",
    "result = strategy(reader.online())\n",
    "print(f'nb_bins = {len(result[\"solution\"])}')\n",
    "print(f'{sorted(result[\"solution\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1dc1ff1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_bins = 8\n",
      "[[10, 252, 127, 106, 10, 12], [46, 127, 12, 252, 84], [106, 252, 85], [127, 37, 106, 127, 106, 10, 10], [127, 252], [252], [252, 252, 10, 9], [442, 9, 37, 10, 12]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrating usage of online version of BestFit algorithm\n",
    "import macpacking.algorithms.online as online\n",
    "strategy: Online = online.BestFit()\n",
    "result = strategy(reader.online())\n",
    "print(f'nb_bins = {len(result[\"solution\"])}')\n",
    "print(f'{sorted(result[\"solution\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b8891b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_bins = 8\n",
      "[[9, 9], [106, 106, 106, 85, 84, 37], [127, 127, 127, 106, 37], [252, 127, 127, 10], [252, 252, 10, 10], [252, 252, 10, 10], [252, 252, 12], [442, 46, 12, 12, 10]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrating usage of offline version of WorstFit algorithm\n",
    "import macpacking.algorithms.offline as offline\n",
    "strategy: Offline = offline.WorstFitDecreasing()\n",
    "result = strategy(reader.online())\n",
    "print(f'nb_bins = {len(result[\"solution\"])}')\n",
    "print(f'{sorted(result[\"solution\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89a99f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_bins = 8\n",
      "[[10, 252, 127, 106, 10], [46, 12, 127, 10, 12, 252, 10], [85, 37, 252, 10, 12], [106, 84, 252], [127, 37, 106, 127, 106], [252, 10, 9, 127], [252, 252], [442, 9]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrating usage of online version of WorstFit algorithm\n",
    "import macpacking.algorithms.online as online\n",
    "strategy: Online = online.WorstFit()\n",
    "result = strategy(reader.online())\n",
    "print(f'nb_bins = {len(result[\"solution\"])}')\n",
    "print(f'{sorted(result[\"solution\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e58e98a",
   "metadata": {},
   "source": [
    "## T3: Measuring Improvement Margin\n",
    "See Report body for further explanation of graphs etc. The graph will open in a new window, so thats why it's not showing in the Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a81e4cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "N1C1W1_A is not optimal\n",
      "N1C1W1_B is not optimal\n",
      "N1C1W1_C is not optimal\n",
      "N1C1W1_D is not optimal\n",
      "N1C1W1_E is not optimal\n",
      "N1C1W1_F is not optimal\n",
      "N1C1W1_G is not optimal\n",
      "N1C1W1_H is not optimal\n",
      "N1C1W1_I is not optimal\n",
      "N1C1W1_J is not optimal\n",
      "N1C1W1_K is not optimal\n",
      "N1C1W1_L is not optimal\n",
      "N1C1W1_M is not optimal\n",
      "N1C1W1_N is not optimal\n",
      "N1C1W1_O is not optimal\n",
      "N1C1W1_P is not optimal\n",
      "N1C1W1_Q is not optimal\n",
      "N1C1W1_R is not optimal\n",
      "N1C1W1_S is not optimal\n",
      "N1C1W1_T is not optimal\n"
     ]
    }
   ],
   "source": [
    "from improvement_margin import Margin\n",
    "from macpacking.algorithms.online import NextFit, MostTerrible, WorstFit, BestFit, RefinedFirstFit\n",
    "from macpacking.algorithms.offline import NextFitDecreasing, WorstFitDecreasing, BestFitDecreasing, RefinedFirstFitDecreasing\n",
    "\n",
    "# Margin class for the determination of of improvement margins for a specified algorithm \n",
    "test_binpp = Margin('optimal_solutions/binpp.csv', NextFit(), 'Next Fit', True, 'N1C1W1')\n",
    "# displays continous results, i.e graph representing the difference of bins from optimal (the graph is displayed in a new window)\n",
    "# ** CLOSE THE GRAPH WINDOW SO THE CELL CAN CONTINUE RUNNING\n",
    "#test_binpp.display_continuous()\n",
    "# displays discrete results, i.e whether the solution is optimal or not\n",
    "test_binpp.display_discrete()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a132d202",
   "metadata": {},
   "source": [
    "## T4: Add Smarter Algorithms\n",
    "See Report body for further explation of algortithm and KPI graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32979df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_bins = 8\n",
      "[[10, 127, 106, 10, 127, 37, 106], [106, 84, 85, 9, 127, 12], [127, 106, 46, 12, 127, 10, 12, 10, 9, 37, 10, 10], [252], [252, 252], [252, 252], [252, 252], [442]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrating usage of online version of the Refined First Fit algorithm\n",
    "import macpacking.algorithms.online as online\n",
    "strategy: Online = online.RefinedFirstFit()\n",
    "result = strategy(reader.online())\n",
    "print(f'nb_bins = {len(result[\"solution\"])}')\n",
    "print(f'{sorted(result[\"solution\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73e68be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_bins = 8\n",
      "[[106, 85, 84, 37, 37, 10, 10, 10, 10, 10, 10, 9], [127, 106, 106, 106, 46, 12, 12, 9], [127, 127, 127, 127, 12], [252], [252, 252], [252, 252], [252, 252], [442]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrating usage of offline version of the Refined First Fit algorithm\n",
    "import macpacking.algorithms.offline as offline\n",
    "strategy: Offline = offline.RefinedFirstFitDecreasing()\n",
    "result = strategy(reader.online())\n",
    "print(f'nb_bins = {len(result[\"solution\"])}')\n",
    "print(f'{sorted(result[\"solution\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565ab1ec",
   "metadata": {},
   "source": [
    "## T5: From Fixed Capacity to Fixed Bins\n",
    "See Report body for further explation of algorithm and KPI graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d89c860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_bins = 8\n",
      "[[252, 106, 106], [252, 106, 106], [252, 127, 37, 12, 10, 10], [252, 127, 37, 12, 10, 10, 9], [252, 127, 46, 12, 10, 9], [252, 127, 84], [252, 127, 85], [442, 10]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrating the baseline integrated using the to_constant_volume() function in the binpacking \n",
    "# library that attempts to solve the problem of multiway number partitioning\n",
    "import macpacking.algorithms.baseline as baseline\n",
    "# initializing number of bins by passing argument into ConstantBinNumber\n",
    "strategy: Offline = baseline.ConstantBinNumber(num_bins=8)\n",
    "result = strategy(reader.offline())\n",
    "print(f'nb_bins = {len(result)}')\n",
    "print(f'{sorted(result)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8dd069f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_bins = 8\n",
      "[[10, 106, 10, 9, 252], [10, 127, 85, 252], [37, 46, 12, 127, 10, 252], [106, 10, 252], [106, 12, 442], [127, 84, 37, 127], [127, 106, 10, 9, 252], [252, 12, 252]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrating the Greedy Algorithm compares with the baseline for multiway number partitioning\n",
    "import macpacking.algorithms.online as online\n",
    "strategy: Offline = offline.GreedyHeuristic(num_bins=8)\n",
    "result = strategy(reader.offline())\n",
    "print(f'nb_bins = {len(result[\"solution\"])}')\n",
    "print(f'{sorted(result[\"solution\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a130e43",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabe0579",
   "metadata": {},
   "source": [
    "### T1 Explanation \n",
    "\n",
    "#### Dataset Explanation\n",
    "There are three datasets included in the repository: binpp, binpp-hard, and jburkardt. Binpp and binpp-hard have the same format, they are given as a long text file in which every line is an integer. The first number represents the number of objects that need to be packed, and the second line represents the maximum weight or capacity a bin can hold. Every subsequent line in the file represents the weight of an object that needs to be packed. Let n be the number of objects that need to be packed and let c be the maximum capacity of the bin. In binpp, n = 50, 100, 200, 500 and c = 100, 120, and 150. Binpp-hard has the same formatting, but the values of n = 200 and c = 100000. In the jburkhardt dataset, the file system is arranged a little differently than the binpp one as there are 3 files for every problem. For problems p01, p02, and p03, c = 100 and n ranges from 9 to 14. For problem p04, c = 524 and n = 33. For each problem, the file ending with c contains the capacity number and the file ending with w contains the weights of the objects that need to be packed. The s file contains an assignment of weights. The values of the n parameter are important to evaluate algorithm performance, as the time complexity of the problem is in terms of n. The longer n is, the longer the algorithm will take to find the number of bins needed to optimally pack the n items.\n",
    "\n",
    "#### SOLID Principles Explanation of UML Diagram\n",
    "![allcomparisons](images/UML_providedcode.png) <br>\n",
    "- Single responsibility <br>\n",
    "The separation of online and offline algorithms implements the single responsibility principle, as all Online and Offline algorithms will be separated into their respective files.\n",
    "Each implementation of a bin packing algorithm is given its own class with its own functions it will use to perform bin packing. By separating each algorithm into its own class with its own functions, the single responsibility principle is followed.\n",
    "\n",
    "- Open closed <br>\n",
    "The use of a BinPacker interface for the bin packing algorithms as well as the separation of Online and Offline algorithms uses the open-closed principle. The program is open to extension of new algorithm classes, but it is closed to modification as BinPacker, Online, and Offline need not be modified in order to accommodate for the addition of algorithms.\n",
    "\n",
    "- Interface segregation <br>\n",
    "Interface segregation was used by the implementation of the BinPacker interface. This interface separates Online and Offline bin packing algorithms, allowing the user to access any of the Online or Offline implementations easily.\n",
    "\n",
    "- Dependency injection <br>\n",
    "The details of each bin packing algorithm implementation are unimportant to the user, and thus, the user does not need to be made aware of the internal functions that are ‘injected’ in each algorithm class. Only the _process() function of each algorithm matters, which is why this design implants dependency injection.\n",
    "\n",
    "#### T2: Algorithms Explanation and Analysis\n",
    "\n",
    "- Next Fit <br>\n",
    "This is the simplest approximate approach to the bin packing problem. This is an online algorithm in which the first item is assigned to the first bin. The weight stream is then considered by increasing indexes. If an item fits in the current bin, it is assigned to that bin. Otherwise, the next bin becomes the current one. The time complexity of the algorithm is O(n), as the algorithm only traverses the weight stream once.\n",
    "\n",
    "- Next Fit Decreasing <br>\n",
    "This is an offline algorithm in which the weights are sorted first into decreasing order. Then, the Next Fit algorithm is applied as discussed above. The time complexity of the algorithm would be O(n + nlogn) which approximates to O(nlogn) since it will take O(nlogn) time to sort the list of weights first using timsort (Python’s default sorting algorithm).\n",
    "\n",
    "- First Fit <br>\n",
    "This is an online algorithm which considers the weight stream according to increasing indices. It assigns each item to the lowest indexed initialized bin into which it fits. When the current item cannot fit into any of the previous initialized bins, a new bin is introduced and the item is assigned to that bin. The time complexity of the algorithm is O(n2), because it has to traverse the weight stream, but also has to loop through previous bins if needed. However, this time complexity can be reduced to O(nlogn) if a self balancing binary tree is used as the data structure.\n",
    "\n",
    "- First Fit Decreasing <br>\n",
    "This is an offline algorithm in which the weights are sorted first into decreasing order. Then, the First Fit algorithm is applied as discussed above. The time complexity of the algorithm would be O(n2 + nlogn) which approximates to O(n2) since it will take O(nlogn) time to sort the list of weights first using timsort (Python’s default sorting algorithm). \n",
    "\n",
    "- Best Fit <br>\n",
    "This is an online algorithm which considers the weight stream according to increasing indices. It  assigns each item to the feasible bin having the smallest space left but can still fit the item. Essentially, it will place each item in the tightest spot. The time complexity of the algorithm is O(n2), because it has to traverse the weight stream, but also has to loop through previous bins if needed in order to determine the tightest spot.\n",
    "\n",
    "- Best Fit Decreasing <br>\n",
    "This is an offline algorithm in which the weights are sorted first into decreasing order. Then, the Best Fit algorithm is applied as discussed above. The time complexity of the algorithm would be O(n2 + nlogn) which approximates to O(n2) since it will take O(nlogn) time to sort the list of weights first using timsort (Python’s default sorting algorithm).\n",
    "\n",
    "- Worst Fit <br>\n",
    "This is an online algorithm which considers the weight stream according to increasing indices. It assigns each item to the feasible bin having the most empty space. Essentially, it will place the item in the least tightest spot to even out the bins. The time complexity of the algorithm is O(n2), because it has to traverse the weight stream, but also has to loop through previous bins if needed in order to determine the least tight spot.\n",
    "\n",
    "- Worst Fit Decreasing <br>\n",
    "This is an offline algorithm in which the weights are sorted first into decreasing order. Then, the Worst Fit algorithm is applied as discussed above. The time complexity of the algorithm would be O(n2 + nlogn) which approximates to O(n2) since it will take O(nlogn) time to sort the list of weights first using timsort (Python’s default sorting algorithm).\n",
    "\n",
    "#### T2: KPI Explanation and Analysis\n",
    "See end of report for all explanations including all algorithms (since metrics for T4 and T5 algorithms were added later).\n",
    "\n",
    "#### T3: Explanation of Improvement Margin\n",
    "For succinctness and brevity in our analysis, we are going to define the following parameters: \n",
    "n  = number of weights\n",
    "c = bin capacity\n",
    "w = list containing the weights\n",
    "o = the number of bins outputted by a bin packing algorithm (essentially, the result)\n",
    "\n",
    "\n",
    "- Improvement Margin Implementation <br>\n",
    "\n",
    "The improvement margin class reads the optimal solutions for a given dataset from a csv file, using read_csv() on the filepath of the optimal solution csv file. This returns the optimal values as a dictionary, which can be accessed when computing the discrete and continuous margins. The class also runs an algorithm using run_algorithm() on the dataset that correlates to the optimal solution file (binpp, bing-hard, or jburkardt). Instead of running it on the entire binpp dataset, the algorithm can be run for just one case in the data set (i.e. N1C1W1), which allows for easier and more specific analysis of the improvement margin results. When the algorithm is being run, the number of bins used in the solution is stored in a dictionary, with the same key as the optimal solutions dictionary. \n",
    "\n",
    "The discrete_margin() method iterates through the keys of the optimal solution, comparing the values of the optimal solution to the corresponding values of the solution found using the algorithm. If they aren’t equal, a boolean value of False is stored in a dictionary along with the same key, as the algorithm did not find the optimal solution to the problem. If the number of bins value is optimal, a boolean value of True is stored in a dictionary along with the same key. The dictionary of booleans is returned as the discrete margin. Similar to the discrete margin, the continuous_margin() method determines whether a solution is optimal, but instead of storing the boolean value, it stores the difference in number of bins used in the optimal solution to the algorithmic solution in a dictionary with corresponding key values. This dictionary of differences is returned as the continuous margin. \n",
    "\n",
    "The display_discrete() method runs read_csv() and run_algorithm() in order for the values to be computed for discrete_margin(). The method then iterates through the items in the dictionary output of discrete_margin(), printing whether the case was optimal or not. The display_continuous() method runs read_csv() and run_algorithm() in order for the values to be computed for continuous_margin(). The method then iterates through the differences in the dictionary output of continuous_margin(), where the keys are in the x axis and the values are in the y axis of a bar graph. The bars of each difference are labeled with the cases they represent and can be analyzed for different cases.\n",
    "\n",
    "- SOLID Principles Explanation <br>\n",
    "\n",
    "Single-Responsibility Principle\n",
    "Each method in this class has its own designated purpose and can be used multiple times by other methods. Computing and displaying both the discrete and continuous margins is separated into their own 4 methods, so that future additions to the improvement margin class can use the outputs of the discrete and continuous margins.\n",
    "Open-Closed Principle\n",
    "The Margin class is initialized with an optimal solution filename, algorithm, algorithm name, is_online boolean, and case:\n",
    "The filename parameter allows the user to read the csv file for any dataset’s optimal solutions, making it open to extending the program to contain new datasets and csv files. Since the dataset also determines the type of DatasetReader used, the run_algorithm() method would need to be made aware of a new reader, but minimal modification is needed in the constructor, as it determines the reader using the optimal solutions filepath. \n",
    "The algorithm, algorithm name, and is_online boolean parameters accommodate for all existing and any new online or offline bin packing algorithms. No part of the Margin class will need to be modified if new algorithms are used, following the open-closed principle.\n",
    "The case parameter is set to a default value of a space character, specifying that the user wishes to compute the margin for the entire dataset. If the parameter is defined as a specific case (i.e. N4C2W2), the margin will only be computed for the contents of that dataset folder. This design choice allows the code to run for an entire dataset or just one case without having to modify any other parts of the code to use the class. This is vital when using analyzing larger datasets such as binpp, where singling out specific cases is required to derive any interpretation of the margin results.\n",
    "\n",
    "\n",
    "##### Explanation of Improvement Margin Graphs\n",
    "\n",
    "- Most Terrible <br>\n",
    "<img src=\"improvmargin_graphs/mt_binpphard.png\" alt=\"drawing\" width=\"700\"/> <br>\n",
    "<img src=\"improvmargin_graphs/mt_jburk.png\" alt=\"drawing\" width=\"700\"/> <br>\n",
    "As expected, the number of bins determined by this algorithm is much larger than the optimal solution. This algorithm will always produce the worst case result no matter what, as it will assign each object to a new bin. So, it will always produce n number of bins.  This explains why the output o determined by the algorithm for the binpp-hard dataset is so far from the optimal solution, as the number of bins determined is about 145 more than the optimal amount for all cases in the dataset. n was 200 for all cases in this dataset. Similar to the binpp-hard, the graph for the jburkardt dataset is also pretty far from the optimal solution due to the poor performance of the Most Terrible bin packing algorithm. <br>\n",
    "\n",
    "- Next Fit <br>\n",
    "<img src=\"improvmargin_graphs/nf_binpphard.png\" alt=\"drawing\" width=\"700\"/> <br>\n",
    "<img src=\"improvmargin_graphs/nf_jburk.png\" alt=\"drawing\" width=\"700\"/> <br>\n",
    "As expected, the optimality of this algorithm is much better than the Most Terrible BinPacking Algorithm. In the binpp-hard dataset, o is always within 8 - 10 bins of the optimal solution. This is a significant improvement margin from the Most Terrible Binpacking Algorithm, which produced a result that was about 145 bins from the optimal solution. This efficiency is also reflected in the jburkardt reader as o is equal to the optimal number of bins for 2 problems and is only 1 bin away from the optimal solution in 2 of the problems. <br>\n",
    "\n",
    "- First Fit <br>\n",
    "<img src=\"improvmargin_graphs/ff_binpphard.png\" alt=\"drawing\" width=\"700\"/> <br>\n",
    "<img src=\"improvmargin_graphs/ff_jburk.png\" alt=\"drawing\" width=\"700\"/> <br>\n",
    "\n",
    "As expected, the optimality of this algorithm is a small amount better than the Next Fit BinPacking Algorithm. In the binpp-hard dataset, o is always within 4-6 bins of the optimal solution. This is a relatively significant improvement margin from the Next Fit Binpacking Algorithm, which produced a result that was about 10 bins from the optimal solution. The graph for the jburkardt dataset is not shown here to avoid redundancy but it is identical to the jburkardt graph  shown for the Next Fit algorithm. However, it can be accessed through the improvement_margin_graphs folder. This efficiency is the same in jburkardt reader is very similar to Next Fit but a little bit better as o is equal to the optimal number of bins for the first 3 problems and o is only 1 bin away from the optimal solution when considering the last problem. <br>\n",
    "\n",
    "- Best Fit <br>\n",
    "<img src=\"improvmargin_graphs/bf_binpphard.png\" alt=\"drawing\" width=\"700\"/> <br>\n",
    "\n",
    "\n",
    "As expected, the optimality of this algorithm is a small amount better than the Next Fit BinPacking Algorithm. In the binpp-hard dataset, o is always within 4-6 bins of the optimal solution. This is a relatively significant improvement margin from the Next Fit Binpacking Algorithm, which produced a result that was about 10 bins from the optimal solution. The graph for the jburkardt dataset is not shown here to avoid redundancy but it is identical to the jburkardt graph  shown for the First Fit algorithm. However, it can be accessed through the improvement_margin_graphs folder. This efficiency is the same in jburkardt reader for First Fit as o is equal to the optimal number of bins for the first 3 problems and o is only 1 bin away from the optimal solution when considering the last problem. <br>\n",
    "\n",
    "- Worst Fit <br>\n",
    "<img src=\"improvmargin_graphs/wf_binpphard.png\" alt=\"drawing\" width=\"700\"/> <br>\n",
    "The optimality of this algorithm is a small amount worse than the First Fit and Best Fit BinPacking Algorithms. The improvement margin for the datasets is very similar to First Fit. In the binpp-hard dataset, o is always within 6 - 7 bins of the optimal solution. This is a relatively significant improvement margin from the Next Fit Bin Packing Algorithm, which produced a result that was about 10 bins from the optimal solution. \n",
    "The graph for the jburkardt dataset is not shown here to avoid redundancy but it is identical to the jburkardt graph  shown for the First Fit algorithm. However, it can be accessed through the improvement_margin_graphs folder. This efficiency is the same in jburkardt reader as Next Fit as o is equal to the optimal number of bins for the first 3 problems and o is only 1 bin away from the optimal solution when considering the last problem. \n",
    "\n",
    "#### T4: Refined First Fit Algorithm\n",
    "The refined first fit algorithm is a modified version of the first fit algorithm, but instead of simply adding the number pieces into bins wherever they fit, they are divided by their size. Then, depending on that, they are sorted into different bins. The pieces are put into categories of “small”, “medium2”, “medium1”, and “a”, that correspond to X, B2, B1, a respectively, from the algorithm description. To create the distinction between these categories, the intervals (0, ⅓], (½, ⅖], (⅖, ½], (½, 1] are used. <br>\n",
    "\n",
    "The data being inputted can be any value, and so the algorithm needed a way to normalize the data to fall within the intervals that would be universal to each dataset. Setting arbitrary values as domains does not guarantee that a value will not be inputted that exceeds these constraints. Therefore, it was instead decided to use the capacity to normalize. It would make more sense to use the max value in the data, since even if the capacity is large that does not mean the values entered will be that large. However, with the online stream, because the future values are unpredictable, it would be impossible to assign a universal max value. Therefore, the capacity is used to normalize, because we know that the data must be less than or equal to the capacity to be placed in a bin. Therefore, to normalize, the interval values are divided by the capacity, and used to sort the data. This ensures that every value is in between 0 and 1, but the size proportionalities are maintained. <br>\n",
    "\n",
    "Once the weight is sorted into a category, an object of the Piece class is created. The Piece class is used to hold information about all the number pieces within the stream. It holds information about the weight and category that are used later on. Then, the piece is added to a bin depending on its category, as defined in the Refined First Fit algorithm. One distinction between this algorithm and First Fit is that instead of using one solution array and adding all bins to this, instead there are 4 different bin arrays for each class defined in RFF - class 1, class 2, class 3, and class 4. This is because the bins of each class have different pieces they can hold. So, the pieces are all sorted into the respective classes, and then can be placed in bins using normal First Fit logic. When a bin needs to be created, a binClasses object is created. This takes the capacity of the bin, the remaining space - which is initialized as the capacity, and is reduced by the pieces weight everytime a new one is added -,  an array pieces (which has all the pieces in the bin), and the classID (which indicated the class of the bin). Once all the pieces have been added to a bin, the 4 class arrays are combined into the solution, and this is what is returned.\n",
    "\n",
    "\n",
    "\n",
    "##### T4 SOLID Principles Explanation in RFF\n",
    "- Single-Responsibility Principle <br>\n",
    "There are Piece, binClasses, and the RefinedFirstFit objects. These are all responsible for different things. The piece object is responsible for representing each data value in the dataset, with its category attribute. Then, each binClass represents the bin, and all its important attributes. It holds within it an array of Piece objects, but the two classes have different responsibilities as they represent different things. Then, the RefinedFirstFit is its own separate job of creating Pieces, deciding which bin category they belong to, and adding the Piece to the binClasses object. \n",
    "Even within the RefinedFirstFit, there is a separation of responsibilities with the functions. For example, the sortPieces() function is only responsible for assigning a category to the piece of data. The add_to_bin() function only determines how to add the piece to a bin. By separating these tasks, readability improves significantly. It also makes modification easier, because it’s obvious what is happening where. <br>\n",
    "\n",
    "- Interface Segregation Principle <br>\n",
    "An example of this principle in the RefinedFirstFit algorithm is the check_bin() function. This function checks if the bin has an A-piece in it, because whether or not it does determines if a B2-piece can be added to that bin. This process is only necessary for the specific situation where a B2-piece is the (mk)th B2-piece. Therefore, it would be redundant and unnecessary to test for the A-piece in every case. Therefore, the add_to_bin() function has a clause that the piece must be “medium2” (which is the same as B2), and be in class 1 (which is when it is a (mk)th B2-piece). Only when these two things are true will the check_bin function be called. Otherwise, it will not be unnecessarily checked.\n",
    "\n",
    "##### T4 Complexity Analysis \n",
    "The time complexity of the algorithm is O(n2), because it has to traverse the weight stream, but also has to loop through previous bins if needed, like checking if there is space remaining or if there is an A-piece in the bin. However, this time complexity could be reduced O(nlogn) if a self balancing binary tree was used as a data structure.\n",
    "\n",
    "\n",
    "#### T5 Greedy Algorithm Explanation\n",
    "The implemented algorithm is designed for multiway number partitioning, i.e balancing the load over a fixed number of bins. This is a little different from the classical bin packing problem as the capacity is not provided but rather the number of bins is. To compare with the baseline (to_constant_volume()) method, we implemented a Greedy algorithm. This algorithm makes the most “locally optimal” or greedy choice at every stage in hopes that it can find a global optimum. This is an offline algorithm, as the list of weights has to be ordered into decreasing order first. The algorithm loops through the list of weights, and each weight is allocated to the bin having the smallest sum of weights (i.e the most empty bin). Unlike the exact greedy algorithm, this algorithm does not guarantee an exact solution every time but the approximations are consistently strong. \n",
    "\n",
    "As mentioned above in benchmarking, we were able to benchmark the Greedy algorithm along with the other offline algorithms. The operations and comparisons KPIs measured in the Greedy implementation are unaffected by the fixed number of bins (an arbitrary value may be used), since no comparisons are performed and only one operation is performed per item. This makes the bench_kpi file reusable even for algorithms that do not specify a capacity. The execution time measurement would vary depending on the fixed number of bins specified using the Greedy algorithm, making it more difficult to generalize and interpret the results of benchmarking Greedy execution time with the other offline algorithms. However, given that Greedy is a linear complexity algorithm, it should have a lower execution time than the quadratic complexity algorithms. To benchmark Greedy Heuristic with the other algorithms, the number of bins value was selected to be 253, since this is the optimal number of bins used for the N4C2W2_A dataset it was tested on, since the optimal number of bins is the most appropriate baseline number to benchmark with.\n",
    "\n",
    "For KPI explanations and implementations for T5, look below.\n",
    "\n",
    "#### KPI Graphs and Explanations for All Graphs\n",
    "\n",
    "##### Bench KPI Explanation <br>\n",
    "By design, each bin packing algorithm returns the solution to the problem, the number of operations, and the number of comparisons performed in the algorithm. These KPIs are incremented throughout the algorithm wherever they occur, and they are returned in a dictionary to be measured and compared when benchmarking. The bench_kpi.py file is responsible for computing the operations and comparisons by running specified algorithms on the entire binpp dataset. The values are plotted based on the number of items/weights the dataset uses, otherwise known as the n values (50, 100, 200). The average number of operations and comparisons across all datasets are averaged for each data point, producing the most generalized representation of the number of operations and comparisons expected from each algorithm, and not just the results of specific cases. This affirms the external validity of our conclusions in the performance of the algorithms implemented. <br>\n",
    "\n",
    "The main() function functions as a runner, calling all the methods and specifying the cases that are to be used to benchmark the algorithms. The list_case_files() function sorts and returns a list of the filenames of the cases specified by the user. The run_bench_kpi() function finds the average KPI measurement for a specified algorithm on a list of cases, returning a dictionary containing the name of the algorithm (used as the label on the plot) and the average computed KPI for the n value key in the folder of cases. This is done by running the algorithm using the run_algorithm() function, which runs the algorithm on a case and returns the solution and required KPI values. The plot_lines() function runs the run_bench_kpi() function for each folder of cases in the binpp dataset and computes the average KPI value, grouping by n values and storing the n value and average pair as a tuple, defining a point in the plot. This occurs for each algorithm, and after iterating through all the cases and computing the average KPI for each n value, the points are appended to a list stored as the value in a dictionary with the key being the algorithm name. After creating the dictionary containing algorithms as keys and lists of point tuples as values, each item in the dictionary is plotted as a line where the x axis is the n value and the y axis is the average number of operations or comparisons. <Br>\n",
    "\n",
    "\n",
    "##### SOLID Principles Explanation\n",
    "- Single-Responsibility Principle\n",
    "The methods list_case_files(), run_bench_kpi(), plot_lines(), and run_algorithm() all have processes used by other methods and can be used separately, making them good processes to implement the single responsibility principle. The run_algorithm() function is especially important to designate its own function to, since it must be used on each algorithm specified in the plot_lines() method. <br>\n",
    "\n",
    "- Open-Closed Principle\n",
    "The KPIs can be measured for any list of any online or offline bin packing algorithm, as the methods take in one or a list of bin packing algorithms and a boolean value which specifies if it is online. This makes the benchmarking open to extension of new algorithms, but closed for modification, as the methods do not need to be modified to be made aware of new algorithms. There is even a parameter in the plot_lines() method to specify more specific details in the title of the graph.\n",
    "Although only two KPIs are measured by the algorithms, additional KPIs such as “insertions” could be added in the future. Regardless, the benchmarking functions can switch between operations and comparisons without having to modify the internal functions.\n",
    "\n",
    "\n",
    "Comparisons <br>\n",
    "<img src=\"graphs/comparisons_all.png\" alt=\"drawing\" width=\"700\"/> <br>\n",
    "As shown above, comparison KPIs were measured for the offline bin packing algorithms on the binpp dataset and all the folders contained within it. Only the graph for the offline algorithms was shown for succinctness and to include Greedy Heuristic, as the comparisons are the same for the online sorting algorithms, and operations used by the pre-sorting is constant across all of these algorithms. Note that the line corresponding to the Next Fit and Worst Fit algorithms cannot be seen because it is directly behind the line corresponding to the Most Terrible and Best Fit algorithms, respectively. Although it looks like the number of comparisons is 0 for both Most Terrible and Next Fit, it is a very small amount relative to the other algorithms so it looks to be 0. We will separate the graphs of quadratic and linear algorithms to better analyze their performances.\n",
    "\n",
    "\n",
    "Linear Comparisons <br>\n",
    "<img src=\"graphs/comparisons_linear.png\" alt=\"drawing\" width=\"700\"/> <br>\n",
    "\n",
    "In this separate graph, we can see that Next Fit, Most Terrible, and Greedy perform linear comparisons. Greedy Heuristic uses no comparisons as it does not have a fixed capacity. As Most Terrible traverses through the weight list, there is one comparison made per item so the number of comparisons will always equal the number of items. It is the same case for Next Fit, so the number of comparisons will always equal the number of items as well. This corresponds with the linear time complexity of the three algorithms. \n",
    "\n",
    "Quadratic Comparisons <br>\n",
    "<img src=\"graphs/comparisons_quadratic.png\" alt=\"drawing\" width=\"700\"/> <br>\n",
    "\n",
    "The number of comparisons correlates to the time complexity of the algorithms, so it makes sense why the comparison plots for Best Fit, Worst Fit, First Fit, and Refined First Fit are also quadratic. Best Fit and Worst Fit have more comparisons than First Fit and Refined First Fit. Best Fit has more comparisons than First Fit. This is because for each item in n, Best Fit also has to loop through previous bins if needed in order to determine the tightest spot. The number of comparisons increases in a quadratic manner as determining the smallest space in the previous bins where the item can fit requires comparison. The number of comparisons is greater than First fit because keeping track of the min (smallest) bin space also requires comparison to find. The number of comparisons corresponds to the O(n2) time complexity of First Fit. Worst Fit has a similar number of comparisons to Best fit. This is because for each item in n, Worst Fit also has to loop through previous bins if needed in order to determine the least tightest spot. The number of comparisons increases in a quadratic manner as determining the largest space in the previous bins where the item can fit requires comparison. Due to its refined nature, Refined Fit requires fewer comparisons than First Fit. This is because with Refined First Fit, each item is sorted into its categories, and then placed in bins unique to these categories. Therefore, when trying to fit an item in a bin, since it only has to look at the specific bins in the class corresponding to the item category, there are significantly less bins that need to be checked. Once a bin is found that the item fits into, it is immediately added. This allows for a reduction of comparisons needed by the algorithm to place an item in a bin.\n",
    "\n",
    "Operations <br>\n",
    "<img src=\"graphs/operations_all.png\" alt=\"drawing\" width=\"700\"/> <br>\n",
    "\n",
    "As shown above, operation KPIs were measured for all algorithms. Only the graph for the offline algorithms was shown for succinctness and to include Greedy Heuristic, as the operations are the same for the online sorting algorithms, and operations used by the pre-sorting is constant across all of these algorithms. Note that the line corresponding to the Next Fit and Worst Fit algorithms cannot be seen because it is directly behind the line corresponding to the Greedy Heuristic and Best Fit algorithms, respectively. We will separate the graphs of linear and quadratic number of operations to better analyze their performances. In this KPI case, linear and quadratic do not reference the time complexity, as the number of operations does not reflect the behaviour of the algorithm but rather the behaviour of the implementation.\n",
    "\n",
    "Linear Operations <br>\n",
    "<img src=\"graphs/operations_linear.png\" alt=\"drawing\" width=\"700\"/> <br>\n",
    "Most Terrible has the lowest number of operations since there are none performed for every item, there is only 1 comparison performed. Next Fit and Greedy come second, as for each item there is only one operation performed. First Fit is third, as there are more operations involved when determining if the item fits into the bin. The number of operations is significantly less than the number of compares since an operation is only performed if the comparison in the “if” clause is true. So the number of operations is actually supposed to be quadratic, but it appears linear because the operation is actually only being performed when a condition is met. Refined First Fit contains the greatest number of operations out of the linear operation algorithms, as additional operations are performed in the add_to_bin(), check_bin(), and sort_pieces() methods. However, these methods are what lead to improved performance in comparisons.\n",
    "\n",
    "Quadratic Operations<br>\n",
    "<img src=\"graphs/operations_quadratic.png\" alt=\"drawing\" width=\"700\"/> <br>\n",
    "Best Fit has a much larger (quadratic) number of operations because it essentially has to loop through all previous bins in order to determine the tightest spot. There is an operation present in the comparison so that’s why the amount of operations is significantly larger than the rest. Same thing occurs for Worst fit, as there is also an operation present in the if clause, so the operation is done either way, not only when a condition is met.\n",
    "\n",
    "##### Execution Times Pyperf Explanation <br>\n",
    "\n",
    "Execution Time <br>\n",
    "<img src=\"graphs/exectime_all.png\" alt=\"drawing\" width=\"700\"/> <br>\n",
    "As shown above, execution time was measured for all algorithms on the N4C2W2_A dataset. Only the graph for the offline algorithms was shown for succinctness and to include Greedy Heuristic and the baseline BenMaier algorithm as python-binpacking, and the execution times are similar for the online sorting algorithms, and time spent pre-sorting is constant across all of these algorithms. Greedy Heuristic was used with a value of 253 for num bins, the optimal number of bins for N4C2W2_A, since the execution time is dependent on the number of items bins, and this number is a suitable baseline to compare the Greedy algorithm with the others. Note that the line corresponding to the Next Fit and Most Terrible algorithms cannot be clearly differentiated since their bars are thin and smaller than the non-linear algorithms. We will separate the graphs of linear and non-linear number of operations to better analyze their performances. \n",
    "\n",
    "Linear Execution Time <br>\n",
    "<img src=\"graphs/exectime_mt_nf.png\" alt=\"drawing\" width=\"700\"/> <br>\n",
    "\n",
    "<img src=\"graphs/exectime_linear.png\" alt=\"drawing\" width=\"700\"/> <br>\n",
    "The two histograms above show linear algorithms including and excluding the Greedy Heuristic, to more clearly visualise the difference between Most Terrible and First Fit. The Most Terrible algorithm has the smallest execution time, as it simply iterates through each item once to put them each in a bin, whereas Next Fit is required to perform more operations, which is consistent with the results seen in the operation KPI analysis above. The Greedy algorithm, although linear in complexity, contains additional partitioning operations that are not counted in the operations measurement (thus there is no difference between Greedy operations and Next Fit operations KPI measurement), but it does contribute to an increase in execution time. This execution time may shift slightly depending on the fixed number of bins specified. However, we may generally assume that a linear complexity algorithm will have a lower execution time than quadratic, making the results of this benchmark consistent. <br>\n",
    "\n",
    "NonLinear Execution Time <br>\n",
    "<img src=\"graphs/exectime_nonlinear.png\" alt=\"drawing\" width=\"700\"/> <br>\n",
    "Out of the non-linear bin packing algorithms, First Fit has the best execution time performance. This is likely because it does not have as many operations as bet fit and worst fit. Since first fit allocates the item into the lowest indexed bin it can fit in, it does not need to determine the tightest or loosest spot. Refined first fit is a second because it has the same overall methodology as First Fit but has additional operations to assign each weight a class depending on if it is “small”, “medium” or large. Best and Worst Fit have similar execution times because a number of operations and comparisons have to be performed in order to determine the “tightest” or “loosest” spot that the item can be allocated to. The baseline algorithm determined from the python binpacking library has the highest execution time. This is likely due to this algorithm having more computational complexities in order to solve the binpacking problem in a more efficient way.\n",
    "\n",
    "\n",
    "### UML For Final Code \n",
    "<img src=\"images/finalcode_UML.png\" alt=\"drawing\" width=\"1500\"/> <br>\n",
    "\n",
    "The SOLID principles encapsulated in this UML are discussed in the explanations from task 1 to 5. Relative imports were used throughout classes to make use of a more modular design. Since classes and files were well-organized by interacting methods, we were able to use relative imports within files in a shared directory instead of absolute imports. For each method, all parameters and outputs were given a type alias where applicable, enhancing readability and validity of the methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36dea3a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "217aefb9-4bf5-4975-9e18-95718b2c47ca",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Self-reflection questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4646f916-24c0-401a-ac38-7aee03e59bf7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As part of the self-reflection dimension of an experiential course, each member of the group is expected to answer to the following four questions:\n",
    "\n",
    "  - What process did you go through to produce this result? (Backward)\n",
    "  - What were your standards for this piece of work? Did you meet your standards? (Inward)\n",
    "  - What the one thing you particularly want people to notice when they look at your work? (Outward)\n",
    "  - What lessons will you keep from this reading/lecture in your professional practice? (Forward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
